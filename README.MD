# ğŸ§¬ LIP â€” Latent Injection Protocol
### Universal Latent Communication for Heterogeneous LLMs

**Status: Gen 6.2 (Stable Research Prototype)**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Reproduction: Verified](https://img.shields.io/badge/Reproduction-Verified-green.svg)]()

---

## ğŸ“– Abstract

LIP (Latent Injection Protocol) enables **direct vector-to-vector communication** between heterogeneous Large Language Models, bypassing natural language (token) bottlenecks.

This repository contains the official implementation of the **Gen 6.2** pipeline, enabling a **DeepSeek-Coder-1.3B** (Source) to drive a **Llama-3-8B** (Target) via a trained bottleneck adapter (2048d â†’ 512d â†’ 4096d).

Key contributions:
1.  **Heterogeneous Latent Mapping:** Translating intent between different embedding spaces.
2.  **Energy Calibration:** Preserving vector magnitude physics during injection.
3.  **Deterministic Injection:** Validated via AB testing on layer -2.

---

## ğŸ› ï¸ Installation & Setup

### 1. Environment
This project requires **Python 3.10+**.
We recommend a fresh virtual environment to avoid conflicts with system-wide PyTorch versions.

```bash
# Create and activate environment
python -m venv venv
# Windows
.\venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 2. Dependencies
Installation is strict to ensure reproducibility. Note: For Windows users with AMD GPUs, torch-directml is supported.

```
Bash

pip install -r requirements.txt
```

### 3. Verify Installation
Run the integration test suite to ensure the environment is sound before downloading heavy models.

```Bash

pytest tests/test_integration.py
```
_(Expected output: 3 passed)_

## ğŸš€ Quickstart: Reproduction Guide
Follow these steps to reproduce the experiments described in the paper.

### Step 1: Data Mining (Demo Mode)
Instead of downloading the full 25k dataset, you can run in --demo mode to process just 100 samples. This downloads the source model, extracts vectors, and prepares the shards.

```
Bash
# Runs extraction for 100 samples (cpu/gpu auto-detect)
python src/pipelines/data_factory.py --config configs/data_factory_config.yaml --demo
```
_Output: datasets/Gen6.1/raw_shards/shard_0.pt_

### Step 2: Training the Adapter
Train the LIP Adapter (Gen 6.2) using the mined shards.

```
Bash
python src/pipelines/trainer.py --config configs/train_config.yaml
```
_Artifacts will be saved to: checkpoints/Gen6.2/_

### Step 3: Inference & "Telepathy" Test
Run the deterministic AB test. This injects the latent vector into Llama-3 and compares the output against a baseline.

```
Bash
python src/pipelines/run_infer.py --config configs/infer.yaml
```
_Expected Result: You should see Llama-3 generating code or text aligned with the prompt without receiving the text prompt directly, driven solely by the injected vector._

### Step 4: Eval Syntax Pass
Run the syntax evaluation to check Python validity of generated code.

```
Bash
python src/scripts/eval_syntax_pass1.py --config configs/infer.yaml
```
_Output: Syntax Pass Rate and CSV `results_syntax_eval.csv`_

## ğŸ§  Examples of Latent Communication (No Text Transmitted)

The following outputs were generated by **Llama-3-8B** receiving *only* the latent vectors from **DeepSeek-Coder-1.3B**. No text prompts were passed between models.

| DeepSeek Intent (Hidden Input) | Llama-3 Execution (Generated Code) | Status |
| :--- | :--- | :--- |
| *"Create a simple Python game loop..."* | `class Game: def __init__(self)... while True: command = input...` | âœ… Success |
| *"Read a CSV file and sum columns..."* | `import pandas as pd... df = pd.read_csv('file.csv')... print(df.sum())` | âœ… Success |
| *"Sentiment analysis using NLTK..."* | `from nltk.sentiment import SentimentIntensityAnalyzer... def analyze(text):...` | âœ… Success |
| *"Update SQL table example..."* | `import sqlite3... c.execute('UPDATE stocks SET qty=? WHERE symbol=?', ...)` | âœ… Success |

*Note: The system achieved 99.7% alignment accuracy on the training set using Hybrid Contrastive Learning.*

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ configs/              # Experiment configurations (YAML)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/             # Model definitions (LIPAdapter) & Loss functions
â”‚   â”œâ”€â”€ integrations/     # PyTorch Hooks for Injection
â”‚   â”œâ”€â”€ pipelines/        # Data Factory, Trainer, Inference Logic
â”‚   â””â”€â”€ scripts/          # Utilities (Graphs, Diagrams)
â”œâ”€â”€ tests/                # Integration tests (pytest)
â”œâ”€â”€ datasets/             # (Created at runtime) Vector shards
â””â”€â”€ checkpoints/          # (Created at runtime) Model weights
```

## ğŸ”¬ Citation
If you use this code in your research, please cite:

```
@misc{silva2025lip,
  title={LIP: A Universal Latent Injection Protocol for Heterogeneous Model Communication},
  author={Silva, Cristiano},
  year={2025},
  publisher={GitHub},
  journal={GitHub repository},
  howpublished={\url{[https://github.com/zigfreud/latent-llm-agent-communication](https://github.com/zigfreud/latent-llm-agent-communication)}}
}
```
